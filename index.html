<head>
    <title>ASH API</title>
	<meta name="viewport" content="width=device-width, initial-scale=1">
	 <link rel="stylesheet" href="styles.css">
</head>

<body>
	<div class="ashHeader">
		<img class="headerImage" src="images/ashLogo.png">
	</div>
	<div class="ashContent">
		<div class=ashContentHeader><b>What is ASH API?</b></div>
		<div class="ashContentLarge">
			ash API is an API and dashboard system that allows for stress detection and analysis using only a user's webcam, or optional GSR (Galvanic Skin response) sensor. This allows for games or software to adapt directly to the user's perceived stress level allowing for unique approaches to concepts such as difficulty and accessibility.
		</div>
		<div class=ashContentHeader><b>What is the our abstract?</b></div>
		<div class="ashContentLarge">
			<i>Modern games offer no satisfying ability to adapt gameplay in response to a player's personal, individual experience with the game. In particular, games do not have any adequate means of assessing or responding to a user’s stress. Stress is important for determining user’s experience: too little stress implies a lack of engagement, and too much stress implies the player is overwhelmed. Existing attempts to adapt gameplay* are severely limited in assessing stress because the only means of interaction between the player and game is the controller, which is impersonal and indirect. In order to adequately assess a player’s stress, a game would need access to physiological data or analyze a player’s expression which would require specialized hardware and software not supplied by any existing game engine or console. The goal of the system is to develop such a utility that connects a game to a player’s perceived level of stress, thereby allowing the game to adapt in response to the user’s experience. </i>
		</div>
	</div>
	
</body>
